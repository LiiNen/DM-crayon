{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from konlpy.tag import  Okt\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "json_list = os.listdir('../news-crawler')\n",
    "json_files = [file for file in json_list if file.endswith('.json')]  \n",
    "data = []\n",
    "df = pd.DataFrame()\n",
    "for i in json_files:\n",
    "    for line in open(('../news-crawler/'+i),\"r\", encoding='utf-8-sig'):\n",
    "        df = pd.concat([df, pd.DataFrame(json.loads(line), columns=['id', 'title', 'content', 'date', 'like'])])  \n",
    "\n",
    "okt = Okt() \n",
    "# okt.analyze  #구(Phrase) 분석\n",
    "# okt.morphs   #형태소 분석\n",
    "# okt.nouns    #명사 분석\n",
    "# okt.pos      #형태소 분석 태깅\n",
    "\n",
    "noun_list = []\n",
    "for content in tqdm(df['content']): \n",
    "    nouns = okt.nouns(content) # 명사만 추출하기, 결과값은 명사 리스트\n",
    "    noun_list.append(nouns)\n",
    "df['nouns'] = noun_list\n",
    "print(df.head())\n",
    "\n",
    "# 문서를 명사 집합으로 보고 문서 리스트로 치환 (tfidfVectorizer 인풋 형태를 맞추기 위해)\n",
    "text = [\" \".join(noun) for noun in df['nouns']]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 5, ngram_range=(1,5))\n",
    "tfidf_vectorizer.fit(text)\n",
    "vector = tfidf_vectorizer.transform(text).toarray()\n",
    "\n",
    "vector = np.array(vector) # Normalizer를 이용해 변환된 벡터\n",
    "model = DBSCAN(eps=0.3,min_samples=6, metric = \"cosine\")\n",
    "# 거리 계산 식으로는 Cosine distance를 이용\n",
    "result = model.fit_predict(vector)\n",
    "df['result'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['result'] != -1]\n",
    "df3 = df2[df2['result'] != 0]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {}\n",
    "\n",
    "\n",
    "for i in df3['result'].unique().tolist():\n",
    "    cluster_dict[i] = df3[df3['result'] == i].title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cluster_dict = sorted(cluster_dict.items(), key=lambda x : len(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "\n",
    "for idx, (cluster_num, texts) in enumerate(sorted_cluster_dict[:10]):\n",
    "    keywords_list = []\n",
    "    id_list = []\n",
    "    like_list = []\n",
    "\n",
    "    for text in texts:\n",
    "        keywords = okt.nouns(text)\n",
    "        keywords_list.extend(keywords)\n",
    "        id_list = df3[df3['result']==cluster_num].id.tolist()\n",
    "        like_list = df3[df3['result']==cluster_num].like.tolist()\n",
    "    standard = set(keywords_list)\n",
    "\n",
    "    final_keyword = []\n",
    "\n",
    "    for keyword in standard:\n",
    "        final_keyword.append((keyword, keywords_list.count(keyword)))\n",
    "\n",
    "    final_keyword.sort(key = lambda x : x[1], reverse=True)\n",
    "    output = [keyword for keyword, num in final_keyword[:3]]\n",
    "\n",
    "    final = []\n",
    "    for id, title, like in zip(id_list, texts, like_list):\n",
    "        id['like'] = like\n",
    "        id['title'] = title\n",
    "        final.append(id)\n",
    "    \n",
    "    final_dict[f\"cluster{idx}\"] = {}\n",
    "    final_dict[f'cluster{idx}']['keyword'] = output\n",
    "    final_dict[f'cluster{idx}']['data'] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
